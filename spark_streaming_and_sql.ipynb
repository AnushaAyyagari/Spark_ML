{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data603_Assignment_9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9618MXJPi4C",
        "outputId": "46512fc3-ff63-4a10-e04a-788c7f39c34b"
      },
      "source": [
        "'''\n",
        "As mentioned in the writeup i am using code from \n",
        "https://www.analyticsvidhya.com/blog/2020/11/a-must-read-guide-on-how-to-work-with-pyspark-on-google-colab-for-data-scientists/\n",
        "to setup the spark environment as i was getting errors while running PySpark in my local environment\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd5cC060Pr11"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeFhDVU8PvQL"
      },
      "source": [
        "!wget -q https://www.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pucjanGP16i"
      },
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZZZxZzVP4zj"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjUmDNAZP7nJ"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqbsdYDeP-GB"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S3R5nOxRQAhj",
        "outputId": "932bbcec-b701-4dae-c9e5-ac2d2c0c96cf"
      },
      "source": [
        "findspark.find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.1.2-bin-hadoop2.7'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czm0aEbGLg-L"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.streaming import StreamingContext\n",
        "from pyspark.sql import SQLContext,SparkSession\n",
        "from pyspark.sql.functions import desc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FUYk0KRLh9i"
      },
      "source": [
        "from collections import namedtuple\n",
        "fields = (\"tag\", \"count\" )\n",
        "Tweet = namedtuple('tweets', fields )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUeFFa2rLl2j"
      },
      "source": [
        "sc = SparkContext()\n",
        "ssc = StreamingContext(sc, 10 )\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHQ_qNG6LrDt"
      },
      "source": [
        "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5556)\n",
        "lines = socket_stream.window( 20 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raWpmB_0MEXk"
      },
      "source": [
        "from collections import namedtuple\n",
        "fields = (\"tag\", \"count\" )\n",
        "Tweet = namedtuple('tweets', fields )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKq1RrIrMGwu"
      },
      "source": [
        "# Use Parenthesis for multiple lines or use \\.\n",
        "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
        "  .filter( lambda word: word.lower().startswith(\"#\") ) # Checks for hashtag calls\n",
        "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
        "  .reduceByKey( lambda a, b: a + b ) # Reduces\n",
        "  .map( lambda rec: Tweet( rec[0], rec[1] ) ) # Stores in a Tweet Object\n",
        "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") ) # Sorts Them in a DF\n",
        "  .limit(10).registerTempTable(\"tweets\") ) ) # Registers to a table."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLboTTSLnBZd"
      },
      "source": [
        "ssc.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4CGfDHnInA"
      },
      "source": [
        "# request to get credentials at http://developer.twitter.com\n",
        "consumer_key    = \"d7IVUccLABfySxxwna1xmg3fx\"\n",
        "consumer_secret = \"NlI09hp4m97hxln4N8iPGijr9utJTINFBTL62eGfV2uuJgoHrK\"\n",
        "access_token    = \"1389687115554959367-onDJTNa1FZ2KkejKjufp1Vb2crlruv\"\n",
        "access_token_secret   = \"BpBAJtqkf1K2kUtvCBSbAZ8bgpehRjGVaWOJJ6EJL5XvH\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rntNZqCnMaT"
      },
      "source": [
        "def twitter_setup():\n",
        "    \"\"\"\n",
        "    Utility function to setup the Twitter's API\n",
        "    with our access keys provided.\n",
        "    \"\"\"\n",
        "    # Authentication and access using keys:\n",
        "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "    auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "    # Return API with authentication:\n",
        "    api = tweepy.API(auth)\n",
        "    return api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVgV2s43nOdq",
        "outputId": "95e0594d-0131-41c6-dbdc-3bec7d24f420"
      },
      "source": [
        "extractor = twitter_setup()\n",
        "\n",
        "# We create a tweet list as follows:\n",
        "#tweets = extractor.user_timeline(screen_name=\"@iamsrk\", count=600)\n",
        "tweets = extractor.search(q=\"#umbc\")\n",
        "\n",
        "print(\"Number of tweets extracted: {}.\\n\".format(len(tweets)))\n",
        "\n",
        "# We print the most recent 5 tweets:\n",
        "#print(\"3 recent tweets:\\n\")\n",
        "for tweet in tweets[:3]:\n",
        "    print(tweet.text)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tweets extracted: 15.\n",
            "\n",
            "Current Temp at Hamilton Str. Prkng Lot D on 11/27/2021, 12:00 is: 39.22. It feels like 31.51. Raining Probability… https://t.co/y9ZJ3hlXJI\n",
            "\n",
            "#Davidson vs #RobertMorris 2pm\n",
            "#Pitt vs #UMBC 2pm\n",
            "#ColoradoSt vs #NorthernColorado 2pm\n",
            "#Nebraska vs #SouthDakota 2p… https://t.co/CODI4ilPLh\n",
            "\n",
            "Current Temp at Hamilton Str. Prkng Lot D on 11/27/2021, 06:00 is: 28.46. It feels like 19.07. Raining Probability… https://t.co/3edHrv0Eu1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "5cK5zq5UMSiI",
        "outputId": "e3eb75c5-6ad4-474b-ffc2-1f3446ecea69"
      },
      "source": [
        "import time\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas\n",
        "%matplotlib inline\n",
        "count = 0\n",
        "while count < 5:\n",
        "    \n",
        "    time.sleep(5)\n",
        "    top_10_tags = SQLContext.sql( 'Select hashtag, count from tweets' )\n",
        "    top_10_df = top_10_tags.toPandas()\n",
        "    display.clear_output(wait=True)\n",
        "    plt.figure( figsize = ( 10, 8 ) )\n",
        "    sns.barplot( x=\"count\", y=\"hashtag\", data=top_10_df)\n",
        "    plt.show()\n",
        "    count = count + 1\n",
        "    print(conut)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4bfba7df539f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtop_10_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Select hashtag, count from tweets'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtop_10_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_10_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sql() missing 1 required positional argument: 'sqlQuery'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrBgHyJAQDxO"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Spark_SQL_config\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esL-y6C-MRCP"
      },
      "source": [
        "import time\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas\n",
        "%matplotlib inline\n",
        "count = 0\n",
        "while count < 5:\n",
        "    \n",
        "    time.sleep(5)\n",
        "    top_10_tags = sqlContext.sql( 'Select hashtag, count from tweets' )\n",
        "    top_10_df = top_10_tags.toPandas()\n",
        "    display.clear_output(wait=True)\n",
        "    plt.figure( figsize = ( 10, 8 ) )\n",
        "    sns.barplot( x=\"count\", y=\"hashtag\", data=top_10_df)\n",
        "    plt.show()\n",
        "    count = count + 1\n",
        "    print(conut)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct2JlCBXQMZv"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqRsLV9wQN1v"
      },
      "source": [
        "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType,FloatType\n",
        "from decimal import Decimal\n",
        "\n",
        "data = [{'student_id':543 , 'Student_name': 'John Smith', 'Phone':'301-304-4044','GPA':3.9 },\n",
        "        {'student_id':544 , 'Student_name': 'Nancy Thomas', 'Phone':'240-340-3444','GPA':3.8 },\n",
        "        {'student_id':545 , 'Student_name': 'Sam Jones', 'Phone':'311-404-4044','GPA':3.9 },\n",
        "        {'student_id':546 , 'Student_name': 'Sara Smith', 'Phone':'303-344-4444','GPA':4.0 },\n",
        "        {'student_id':547 , 'Student_name': 'Harry Spark', 'Phone':'301-304-4934','GPA':3.6 },\n",
        "        {'student_id':548 , 'Student_name': 'Hollie Mason', 'Phone':'344-304-4044','GPA':2.5 },\n",
        "        {'student_id':549 , 'Student_name': 'Jeff Rose', 'Phone':'301-888-4044','GPA':3.0 },\n",
        "        {'student_id':550 , 'Student_name': 'David Munroe', 'Phone':'301-304-9999','GPA':3.9 },\n",
        "        {'student_id':551 , 'Student_name': 'Neal Armstrong', 'Phone':'387-304-4044','GPA':3.2 },\n",
        "        {'student_id':552 , 'Student_name': 'Ryan Williams', 'Phone':'301-361-4044','GPA':3.6 },\n",
        "        {'student_id':553 , 'Student_name': 'Devi Priya', 'Phone':'301-304-6666','GPA':3.7 },\n",
        "        {'student_id':554 , 'Student_name': 'Newt Potter', 'Phone':'301-304-5555','GPA':3.5 }\n",
        "        ]\n",
        "\n",
        "schema = StructType([\n",
        "    StructField('student_id', IntegerType(), False),\n",
        "    StructField('Student_name', StringType(), False),\n",
        "    StructField('Phone', StringType(), False),\n",
        "    StructField('GPA', FloatType(), True),\n",
        "])\n",
        "\n",
        "# Create data frame\n",
        "df = spark.createDataFrame(data,schema)\n",
        "print(type(df))\n",
        "print(df.schema)\n",
        "df.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuNmaLUBVOLU"
      },
      "source": [
        "from pyspark.sql.functions import when,col\n",
        "\n",
        "\n",
        "student_grade=df.withColumn(\"GPA\",when((col(\"GPA\")>=3.6) & (col(\"GPA\")<=4.0),\"A\").when((col(\"GPA\")>=3.2) & (col(\"GPA\")<=3.6),\"B\").when((col(\"GPA\")>=2.8) & (col(\"GPA\")<=3.2),\"C\" ).otherwise(\"Fail\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PM4L62Zjtaw"
      },
      "source": [
        "student_grade.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2E6b9noklAm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "pandas_dataframe = student_grade.toPandas()\n",
        "abc=pandas_dataframe.groupby('GPA')\n",
        "#plt.figure(figsize=(10,10))\n",
        "abc.count().plot(kind='bar',figsize=(10,5))\n",
        "#plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}